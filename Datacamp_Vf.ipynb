{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bd92c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a3b2e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load train and test set directories\n",
    "#resize the images\n",
    "image_size=[224,224]\n",
    "train_dir = \"/Users/saman/OneDrive/Documents/EFREI/Datacamp/chest_xray/train\"\n",
    "test_dir=\"/Users/saman/OneDrive/Documents/EFREI/Datacamp/chest_xray/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c403f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre_trained model\n",
    "vgg = VGG16(input_shape=image_size + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a353a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b0c3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting number of output classes\n",
    "file = glob('/Users/saman/OneDrive/Documents/EFREI/Datacamp/chest_xray/train/*')\n",
    "# our layers\n",
    "x = Flatten()(vgg.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c786575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prediction = Dense(len(file), activation='softmax')(x)\n",
    "# Create a Model object\n",
    "base_model = Model(inputs=vgg.input, outputs=prediction)\n",
    "# See the layer and parameter summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a84833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "base_model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b56ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bf2012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5232 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image data generator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Making sure that we provide the same target size as initialied for the image size\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/Users/saman/OneDrive/Documents/EFREI/Datacamp/chest_xray/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 10,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('/Users/saman/OneDrive/Documents/EFREI/Datacamp/chest_xray/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 10,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1d1b37ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "524/524 [==============================] - 722s 1s/step - loss: 0.2262 - accuracy: 0.9247 - val_loss: 0.2469 - val_accuracy: 0.9215\n",
      "Epoch 2/2\n",
      "524/524 [==============================] - 856s 2s/step - loss: 0.1712 - accuracy: 0.9459 - val_loss: 0.3051 - val_accuracy: 0.9199\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "r = base_model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=2,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9b9e9476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.22620749473571777, 0.17115826904773712],\n",
       " 'accuracy': [0.9246941804885864, 0.9459097981452942],\n",
       " 'val_loss': [0.24689170718193054, 0.30510619282722473],\n",
       " 'val_accuracy': [0.9214743375778198, 0.9198718070983887]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fab1b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "base_model.save('chest_xray.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3a8c5846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "63/63 [==============================] - 62s 982ms/step - loss: 0.3051 - accuracy: 0.9199\n",
      "test loss, test acc: [0.3051062226295471, 0.9198718070983887]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model \n",
    "print(\"Evaluate test data\")\n",
    "results = base_model.evaluate(test_set, batch_size=16)\n",
    "print(\"Test loss, Test accuracy:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20a1f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfe369ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=load_model('chest_xray.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41ab6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test our model\n",
    "image=load_img(r'C:\\Users\\saman\\OneDrive\\Documents\\EFREI\\Datacamp\\chest_xray\\train\\PNEUMONIA\\BACTERIA-92115-0001.jpeg',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2138c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58854ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1b393d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data=preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93894e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[[8.700746e-14 1.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "categories=base_model.predict(image_data)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9769c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6447812e-21 1.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(categories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b34a1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=int(categories[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "106049e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person is Affected By PNEUMONIA\n"
     ]
    }
   ],
   "source": [
    "if result==0:\n",
    "    print(\"PNEUMONIA\")\n",
    "else:\n",
    "    print(\"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09deb335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
